{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "from interval_bounds import *\n",
    "from data_generation import *\n",
    "from ridge_poisoning import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # number of data points\n",
    "m = 5 # number of features\n",
    "sigma = 0.1\n",
    "lamb = 10\n",
    "rho = 1\n",
    "X, y, w = gen_synthetic_normal(n,m,sigma)\n",
    "y = np.sign(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_upper, U_lower = find_interval_bounds_infty_uncertainty(X, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lambda X: np.linalg.norm(X@np.linalg.pinv(X)@np.sign(y)-np.sign(y))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (200, 5)\n",
      "Shape of y:  (200, 1)\n",
      "Shape of w:  (5, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of y: \", y.shape)\n",
    "print(\"Shape of w: \", w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nominal Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, w_hat = solve_nominal(X,y,lamb=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  82.67110119197339\n",
      "76.31449617558687\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: \", loss)\n",
    "print(l(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, w_hat = solve_robust(X,y,rho=rho,lambda_=lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  199.99998829818998\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisoned Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (200, 5)\n",
      "Shape of y:  (200, 1)\n",
      "Shape of w:  (5, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of y: \", y.shape)\n",
    "print(\"Shape of w: \", w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "print((y.T@X).shape)\n",
    "print((np.ones((m+1,m+1))[m:m+1,0:m]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hats = []\n",
    "losses = []\n",
    "losses_svm = []\n",
    "losses_log = []\n",
    "losses_dt = []\n",
    "dt_depth = []\n",
    "dt_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "rhos = list(range(0,25,1))\n",
    "for rho in rhos:\n",
    "    print(rho)\n",
    "    rho /= 10\n",
    "    _, X_hat, _ = solve_poisoned_relaxed(X,y,lamb=lamb,rho=rho, mu=10)\n",
    "    X_hats.append(X_hat)\n",
    "    losses.append(l(X_hat))\n",
    "    \n",
    "    clf = svm.SVC(gamma=\"auto\")\n",
    "    clf.fit(X_hat, np.sign(y))\n",
    "    y_pred = clf.predict(X_hat)\n",
    "    losses_svm.append(hinge_loss(np.sign(y), y_pred))\n",
    "    \n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(X_hat, np.sign(y))\n",
    "    y_pred = logisticRegr.predict(X_hat)\n",
    "    losses_log.append(log_loss(np.sign(y), y_pred))\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_hat, np.sign(y))\n",
    "    dt_depth.append(clf.tree_.max_depth)\n",
    "    dt_nodes.append(clf.tree_.node_count)\n",
    "    y_pred = clf.predict(X_hat)\n",
    "    losses_dt.append(hinge_loss(np.sign(y), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rhos,losses)\n",
    "plt.figure()\n",
    "plt.plot(rhos,losses_svm)\n",
    "plt.figure()\n",
    "plt.plot(rhos,losses_log)\n",
    "plt.figure()\n",
    "plt.plot(rhos,losses_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plot(a,a_name,b,b_name,rhos=rhos):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('rho')\n",
    "    ax1.set_ylabel(a_name, color=color)\n",
    "    ax1.plot(rhos, a, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel(b_name, color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(rhos, b, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot(losses,\"ridge\",losses_svm,\"svm\")\n",
    "compare_plot(losses,\"ridge\",losses_log,\"logistic\")\n",
    "compare_plot(losses,\"ridge\",losses_dt,\"decision tree\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"rho vs max depth\")\n",
    "plt.plot(rhos,dt_depth)\n",
    "plt.figure()\n",
    "plt.title(\"rho vs number of nodes\")\n",
    "plt.plot(rhos,dt_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17889790103590042,\n",
       " 1.6949104333203442,\n",
       " 27.37100476237688,\n",
       " 87.87309834523623,\n",
       " 87.87309834510754]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17889790103590042, 1.6949104333203442, 27.37100476237688, 87.87309834523623, 87.87309834510754]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.78118784e-01,  3.52927076e-01, -4.09136561e-01,\n",
       "        -2.12264210e-02, -6.60611649e-01],\n",
       "       [-2.13247521e-01,  2.59850113e-01,  5.09189017e-01,\n",
       "         2.54386016e+00,  8.99976719e-01],\n",
       "       [ 2.40777127e-01, -3.67606043e-01, -9.31911187e-01,\n",
       "         1.89263560e+00,  6.90481148e-01],\n",
       "       [-7.02769002e-02,  1.38296461e+00,  3.91551629e-01,\n",
       "         1.84175484e-01,  5.42097293e-01],\n",
       "       [-1.23223850e+00,  8.33697344e-01, -2.21839023e-01,\n",
       "        -2.14267937e-01, -7.63434549e-01],\n",
       "       [-4.59755439e-01, -2.52895784e-04, -7.23747233e-01,\n",
       "         1.00974660e+00, -6.85070702e-01],\n",
       "       [-1.85136362e-01, -1.34909571e+00,  7.08492644e-01,\n",
       "        -6.88432938e-01, -8.58083513e-01],\n",
       "       [-4.20082436e-02, -1.57498859e+00, -9.62670475e-02,\n",
       "         9.19176729e-01, -1.65208489e+00],\n",
       "       [ 3.20996910e-01,  1.94801604e+00,  7.02428568e-01,\n",
       "         6.83462744e-04,  4.09833767e-01],\n",
       "       [ 2.19232676e-01,  2.45556027e-01,  1.77046019e+00,\n",
       "        -1.56165894e+00, -9.05615971e-01],\n",
       "       [-1.28070380e-01,  3.55426119e-01, -1.65177593e+00,\n",
       "         1.01460466e-01, -1.88498544e+00],\n",
       "       [-5.36392799e-01,  1.15013197e-01,  1.55075752e-01,\n",
       "         3.44582914e-01, -3.68362505e-01],\n",
       "       [-5.47776498e-01,  1.13338895e+00, -1.33413696e+00,\n",
       "         1.33929362e+00,  1.80824871e+00],\n",
       "       [ 5.56482094e-01,  5.46612159e-01,  1.18870549e-01,\n",
       "        -9.41391019e-02,  7.75905413e-01],\n",
       "       [-2.01633528e+00,  6.65864847e-01, -1.13375427e-01,\n",
       "        -8.49974075e-01, -1.01765950e+00],\n",
       "       [-8.76825585e-01, -1.10302045e+00, -7.69092575e-01,\n",
       "        -2.07680149e+00, -4.35643684e-01],\n",
       "       [ 5.26630501e-01,  1.14715993e+00, -8.14411085e-01,\n",
       "        -2.27112480e+00, -1.38483055e+00],\n",
       "       [-1.06640793e+00,  1.32086584e+00,  1.07527407e-01,\n",
       "        -6.50030542e-01, -1.19389697e+00],\n",
       "       [ 1.47162916e+00,  2.61698981e+00, -7.36260107e-02,\n",
       "         2.81022954e+00, -1.42265323e+00],\n",
       "       [-2.99174275e-01,  1.44963965e+00,  1.73538023e-01,\n",
       "        -4.53744531e-01,  4.05355159e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import hinge_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "\n",
      "0.1\n",
      "0.0\n",
      "\n",
      "0.6\n",
      "0.0\n",
      "\n",
      "0.6\n",
      "0.0\n",
      "\n",
      "0.6\n",
      "0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_hats)):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_hats[i], np.sign(y))\n",
    "    y_pred = clf.predict(X_hats[i])\n",
    "    print(hinge_loss(np.sign(y), y_pred))\n",
    "\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X, np.sign(y))\n",
    "    y_pred = clf.predict(X)\n",
    "    print(hinge_loss(np.sign(y), y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1814.672832323216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anandsranjan/opt/anaconda3/envs/ee227b_env/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_hat in X_hats:\n",
    "    plt.figure()\n",
    "    plt.xlim(-3,3)\n",
    "    plt.ylim(-3,3)\n",
    "    for i in range(X_hat.shape[0]):\n",
    "        plt.scatter(X_hat[i],y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_hat in X_hats:\n",
    "    print(np.linalg.norm(X_hat-X,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
